{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Description\n",
        "\n",
        "We'll build an **AI fashion assistant**, using a fashion shop dataset from HuggingFace for indexing, and set up a RAG chain to process user queries and generate responses.\n",
        "\n",
        "## Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "RAG a technique that enhances the knowledge of language models by integrating additional data.\n",
        "\n",
        "A RAG application has two main components:\n",
        "\n",
        "### 1. Indexing:\n",
        "\n",
        "Ingest and index data from a specific source, typically done offline.\n",
        "\n",
        "\n",
        "### 2. Retrieval and Generation:\n",
        "\n",
        "During runtime, process the user's query, retrieve relevant data, and generate a response.\n",
        "\n"
      ],
      "metadata": {
        "id": "NGWaXxyrTFxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "### 1. OpenAI API Key\n",
        "We use `OpenAI embedding model` for embedding generation.\n",
        "\n",
        "### 2. MongoDB Atlas connection string\n",
        "We store the embedding in `MongoDB Atlas`, which is our vector store.\n",
        "\n",
        "### 3. LangChain API key\n",
        "We pull some library from LangChain hub."
      ],
      "metadata": {
        "id": "awg_kaFuqoUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries dependency and configuration setup"
      ],
      "metadata": {
        "id": "YkZl4_GRjTBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install project dependencies\n",
        "Run the cell below to install the required dependencies."
      ],
      "metadata": {
        "id": "RUFWBdMByEjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain>=0.0.231 langchain-openai langchain-community \\\n",
        "langchain_mongodb pymongo langsmith \\\n",
        "openai tiktoken datasets pandas argparse"
      ],
      "metadata": {
        "id": "lH58WPsDEd-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Credential setup, MongoDB and embedding model config\n",
        "\n",
        "First, add these credentials to your Google Colab's Secrets:\n",
        "- OPENAI_API_KEY\n",
        "- LANGCHAIN_API_KEY\n",
        "- MONGODB_CONN_STRING"
      ],
      "metadata": {
        "id": "eaFAciC39Jwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# langchain lib relies on these env var\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "# mongoDB\n",
        "mongodb_conn_string = userdata.get('MONGODB_CONN_STRING')\n",
        "db_name = \"fashion_shop_faq\"\n",
        "collection_name = \"faq_assistant\"\n",
        "\n",
        "# openAI model for embedding\n",
        "ai_model = \"text-embedding-3-small\"\n",
        "\n",
        "# embedding vector dimension\n",
        "vector_dimension = 512"
      ],
      "metadata": {
        "id": "JEvFCrjb-dLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Indexing Phase\n",
        "\n",
        "In this phase, we will load the fashion dataset from HuggingFace, generate embedding for it, and store it in MongoDB Atlas."
      ],
      "metadata": {
        "id": "2H61bP9Pfebq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to MongoDB Atlas"
      ],
      "metadata": {
        "id": "7zCg7Q6byRxw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHjleA6-rhKI"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from pymongo import MongoClient\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "\n",
        "# Connect to MongoDB Atlas\n",
        "client = MongoClient(mongodb_conn_string)\n",
        "db = client[db_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "print(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up OpenAI Embedding model\n",
        "Use OpenAI \"text-embedding-3-small\" as the embedding model, and set the vector dimension.\n",
        "\n",
        "This is used to generate embedding for the dataset."
      ],
      "metadata": {
        "id": "cs_O7NA9QkIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI embeddings\n",
        "embeddings = OpenAIEmbeddings(model=ai_model, dimensions=vector_dimension)\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "lKq__-seQcqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the dataset from HuggingFace, and prepare it for embedding generation\n",
        "Dataset is loaded from HuggingFace and converted into Pandas dataframe.\n",
        "\n",
        "Then the \"Question\" and \"Answer\" fields are combined into a single field for embedding generation."
      ],
      "metadata": {
        "id": "z8kBGWx5M0A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(\"Quangnguyen711/Fashion_Shop_Consultant\", split=\"train\")\n",
        "\n",
        "# Convert dataset to Panda DataFrame\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(df.head(5))\n",
        "\n",
        "# Only keep records where the Question and Answer fields are not null\n",
        "df = df[df[\"Question\"].notna() & df[\"Answer\"].notna()]\n",
        "\n",
        "# Combine Question and Answer fields into a single text field\n",
        "# axis=1: This means the function is applied row-wise\n",
        "df[\"text\"] = df.apply(lambda row: f\"[Question]{row['Question']}[Answer]{row['Answer']}\", axis=1)\n",
        "\n",
        "# Convert the combined text column to a list of strings\n",
        "texts = df[\"text\"].tolist()"
      ],
      "metadata": {
        "id": "KDaG1XHOMZz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate embedding and store in vector store.\n",
        "Generate embedding in batches, and store it together with the original `question + answer` string in MongoDB Atlas.\n",
        "\n",
        "`tiktoken` is used to calculate the number of token used to generate embeddings."
      ],
      "metadata": {
        "id": "CSSp0wT8ZHC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer for the specific model\n",
        "tokenizer = tiktoken.encoding_for_model(ai_model)\n",
        "\n",
        "# Initialize a variable to keep track of the total tokens used\n",
        "total_tokens_used = 0\n",
        "\n",
        "# Define a reasonable batch size\n",
        "batch_size = 50\n",
        "\n",
        "# Process the dataset in batches\n",
        "for i in range(0, len(texts), batch_size):\n",
        "    batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "    # Calculate total tokens used for the current batch\n",
        "    batch_tokens_used = sum(len(tokenizer.encode(text)) for text in batch_texts)\n",
        "    total_tokens_used += batch_tokens_used\n",
        "\n",
        "    # Generate embeddings for the current batch\n",
        "    embeddings_list = embeddings.embed_documents(batch_texts)\n",
        "\n",
        "    # Prepare documents with embeddings to insert into MongoDB\n",
        "    documents = []\n",
        "    for j, (index, row) in enumerate(df.iloc[i:i + batch_size].iterrows()):\n",
        "        document = {\n",
        "            \"text\" : row[\"text\"],\n",
        "            \"embedding\": embeddings_list[j]\n",
        "        }\n",
        "\n",
        "        # print (document)\n",
        "        documents.append(document)\n",
        "\n",
        "    # Insert the batch of documents into MongoDB\n",
        "    collection.insert_many(documents)\n",
        "\n",
        "    # Print total tokens used in the current batch\n",
        "    print(f\"Processed and inserted batch {i // batch_size + 1}, tokens used : {batch_tokens_used}\")\n",
        "\n",
        "print(f\"Embeddings generated and stored in MongoDB! Total tokens used: {total_tokens_used}\")"
      ],
      "metadata": {
        "id": "-3CAkNl-ZLUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Close MongoDB connection"
      ],
      "metadata": {
        "id": "OV6MeLq7TDd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the MongoDB connection\n",
        "client.close()"
      ],
      "metadata": {
        "id": "Z08-_S0ISnHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Retrieval and Generation Phase\n",
        "\n",
        "Here we set up a **fashion assistant** which process user's query.\n",
        "\n",
        "In the retriever, relevant data is retrieved from MongoDB Atlas based on user's query. First, we need to create a vector search index for our collection in MongoDB, as below:\n",
        "\n",
        "**MongoDB Atlas -> Atlas Vector Search -> JSON Editor:**\n",
        "\n",
        "Select your database and collection accordingly, set Index Name as \"vector_index\", and configure the JSON value as below:\n",
        "\n",
        "```\n",
        "{\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"type\": \"vector\",\n",
        "      \"path\": \"embedding\",\n",
        "      \"numDimensions\": 512,\n",
        "      \"similarity\": \"cosine\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2RSTsC2lwrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to MongoDB Atlas"
      ],
      "metadata": {
        "id": "0rKCQicqUItA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from pymongo import MongoClient\n",
        "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Connect to MongoDB Atlas\n",
        "client = MongoClient(mongodb_conn_string)\n",
        "db = client[db_name]\n",
        "collection = db[collection_name]\n",
        "\n",
        "print(client)"
      ],
      "metadata": {
        "id": "5v6WzEx3UHvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up OpenAI Embedding model\n",
        "\n",
        "This is used to generate embedding for user's query."
      ],
      "metadata": {
        "id": "WBZd0nMiUPOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI embeddings\n",
        "embeddings = OpenAIEmbeddings(model=ai_model, dimensions=vector_dimension)\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "0t4pLuajUMdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up MongoDB Atlas vector search as the retriever.\n",
        "\n",
        "By default, the retriever returns 4 closest match to user's query from the vector store."
      ],
      "metadata": {
        "id": "ymhxbxtzBxE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"vector_index\"\n",
        "\n",
        "# Initialize MongoDBAtlasVectorSearch with correct keys\n",
        "vectorStore = MongoDBAtlasVectorSearch(\n",
        "    collection=collection,\n",
        "    embedding=embeddings,        # Your embedding model\n",
        "    text_key=\"text\",             # Field in MongoDB for the text you want to retrieve\n",
        "    embedding_key=\"embedding\",   # Field in MongoDB for the stored embeddings\n",
        "    index_name=index_name,       # Name of Vector Index in MongoDB Atlas\n",
        "    relevance_score_fn=\"cosine\"  # Use cosine similarity\n",
        ")\n",
        "\n",
        "print(vectorStore)\n",
        "\n",
        "retriever = vectorStore.as_retriever()"
      ],
      "metadata": {
        "id": "aZtJPC4fmMcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enter your query to the fashion assistant"
      ],
      "metadata": {
        "id": "Nglc7WwPJj1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"outfit suggestion for wedding dinner\" # @param {\"type\":\"string\",\"placeholder\":\"What to wear for dinner?\"}\n"
      ],
      "metadata": {
        "id": "6jZWY3HeEyvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG chain to process user's query"
      ],
      "metadata": {
        "id": "KNhEDSS0EjIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    print(\"\\nRetriver - relevant docs:\")\n",
        "    print(\"--------------------------------------\")\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        print(f\"{i+1}: {doc.page_content}\")\n",
        "\n",
        "    return \"\\n\\n\".join(\n",
        "        [f\"{doc.page_content}\" for doc in docs]\n",
        "    )\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "response = rag_chain.invoke(query)\n",
        "\n",
        "print(\"\\nRAG Chain Response:\")\n",
        "print(\"-------------------\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "CvCxAcaIGgUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Close MongoDB connection"
      ],
      "metadata": {
        "id": "A5L1I1zdIDeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the MongoDB connection\n",
        "client.close()"
      ],
      "metadata": {
        "id": "e1WNZGQlIBYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}